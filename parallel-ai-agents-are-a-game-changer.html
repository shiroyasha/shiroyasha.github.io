<!doctype html>
<html itemscope itemtype="http://schema.org/Article">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv='X-UA-Compatible' content='IE=edge;chrome=1' />
    <link rel="alternate" type="application/atom+xml" title="Morning Coffee" href="/feed.xml" />

    <link rel="shortcut icon" href="favicon.svg">

    <meta name="viewport" content="width=device-width, initial-scale=1">

      <title>Parallel AI Agents Are a Game Changer &mdash; by Igor ≈†arƒçeviƒá</title>

    <!-- Place this data between the <head> tags of your website -->
      <meta name="description" content="I‚Äôve been in this industry long enough to watch technologies come and go. I‚Äôve
seen the excitement around new frameworks, the promises of revolutionary..." />

      <!-- Schema.org markup for Google+ -->
      <meta itemprop="name" content="Parallel AI Agents Are a Game Changer">
      <meta itemprop="description" content="I‚Äôve been in this industry long enough to watch technologies come and go. I‚Äôve
seen the excitement around new frameworks, the promises of revolutionary...">
      <meta itemprop="image" content="http://morningcoffee.io/images/2025-09-02-parallel-ai-agents-are-a-game-changer.png">

      <!-- Twitter Card data -->
      <meta name="twitter:card" content="summary_large_image">
      <meta name="twitter:site" content="@igor_sarcevic">
      <meta name="twitter:title" content="Parallel AI Agents Are a Game Changer">
      <meta name="twitter:description" content="I‚Äôve been in this industry long enough to watch technologies come and go. I‚Äôve
seen the excitement around new frameworks, the promises of revolutionary...">
      <meta name="twitter:creator" content="@igor_sarcevic">
      <!-- Twitter summary card with large image must be at least 280x150px -->
      <meta name="twitter:image:src" content="http://morningcoffee.io/images/2025-09-02-parallel-ai-agents-are-a-game-changer.png">

      <!-- Open Graph data -->
      <meta property="og:title" content="Parallel AI Agents Are a Game Changer" />
      <meta property="og:type" content="article" />
      <meta property="og:url" content="http://" />
      <meta property="og:image" content="http://morningcoffee.io/images/2025-09-02-parallel-ai-agents-are-a-game-changer.png" />
      <meta property="og:description" content="I‚Äôve been in this industry long enough to watch technologies come and go. I‚Äôve
seen the excitement around new frameworks, the promises of revolutionary..." />
      <meta property="article:published_time" content="2025-09-02 00:00:00 UTC" />

    <link href="/stylesheets/site.css" rel="stylesheet" />
  </head>
  <body>
    <div id="main" role="main" class="px-4">
        <div class="max-w-2xl mx-auto">

    <a class="block flex flex-col items-center justify-center mt-10" href="/">
      <svg
        xmlns="http://www.w3.org/2000/svg"
        width="24"
        height="24"
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        stroke-width="2"
        stroke-linecap="round"
        stroke-linejoin="round"
      >
        <path d="M3 14c.83 .642 2.077 1.017 3.5 1c1.423 .017 2.67 -.358 3.5 -1c.83 -.642 2.077 -1.017 3.5 -1c1.423 -.017 2.67 .358 3.5 1" />
        <path d="M8 3a2.4 2.4 0 0 0 -1 2a2.4 2.4 0 0 0 1 2" />
        <path d="M12 3a2.4 2.4 0 0 0 -1 2a2.4 2.4 0 0 0 1 2" />
        <path d="M3 10h14v5a6 6 0 0 1 -6 6h-2a6 6 0 0 1 -6 -6v-5z" />
        <path d="M16.746 16.726a3 3 0 1 0 .252 -5.555" />
      </svg>
      <div class="text-center mt-2 text-sm">
        <span class="uppercase tracking-widest text-xs bg-yellow-200 px-2.5 py-1 font-semibold">Morning Coffee</span>
      </div>
    </a>

    <article class="mt-10">
      <div class="mb-10">
        <h1 class="text-[30px] font-extrabold mb-2 text-center leading-[1.2]">Parallel AI Agents Are a Game Changer</h1>

        <div class="flex gap-1.5 items-center justify-center text-stone-500 text-sm">
          September  2, 2025 <span>&bull;</span> Igor ≈†arƒçeviƒá
        </div>
      </div>

      <div class="content prose md:prose-lg prose-zinc prose-p:leading-[1.5] mx-auto">
        <p>I&rsquo;ve been in this industry long enough to watch technologies come and go. I&rsquo;ve
seen the excitement around new frameworks, the promises of revolutionary tools,
and the breathless predictions about what would &ldquo;change everything.&rdquo; Most of the
time, these technologies turned out to be incremental improvements wrapped in
marketing hyperbole.</p>

<p>But parallel agents? This is different. This is the first time I can say,
without any exaggeration, that I&rsquo;m witnessing technology that will fundamentally
transform how we develop software.</p>

<h2>How We Got Here</h2>

<p>To understand where we are today, we need to look at the full history of AI-assisted
coding. It started with GitHub Copilot, which introduced the concept of AI pair
programming. Copilot could autocomplete code as you typed, suggesting functions,
completing implementations, and helping with repetitive tasks.</p>

<p>Then came the AI-powered editors like Windsurf and Cursor. These took the concept
further by integrating AI deeply into the development environment. Instead of just
autocomplete, you could have conversations with AI about your code, ask for
refactoring suggestions, and get help with debugging. The AI understood your
entire codebase and could provide contextual assistance.</p>

<p>This year, we&rsquo;ve been working with what&rsquo;s called &ldquo;vibe coding&rdquo; ‚Äî AI tools where you
describe what you want in natural language, and the AI generates complete functions,
classes, or implementations from scratch. You tell it &ldquo;create a sign up form with
google, github, and microsoft login options&rdquo; and it produces working code that
captures the vibe of what you asked for.</p>

<p>The term &ldquo;vibe coding&rdquo; was coined by Andrej Karpathy in
<a href="https://x.com/karpathy/status/1886192184808149383">this tweet</a>, which perfectly
captured what this new way of programming felt like.</p>

<blockquote><p lang="en" dir="ltr">There&rsquo;s a new kind of coding I call &ldquo;vibe coding&rdquo;, where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It&rsquo;s possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper‚Ä¶</p>&mdash; Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1886192184808149383?ref_src=twsrc%5Etfw">February 2, 2025</a></blockquote>

<p>This was genuinely revolutionary. Suddenly, you could generate boilerplate code,
build simple functions, create UI components, and even tackle complex implementations
just by describing them. Many engineers adopted these tools and found them
incredibly useful for certain types of work.</p>

<p>The technology worked well enough that it changed how many of us approached
coding. Instead of starting from a blank file, you could start with a working
implementation and refine from there. It made prototyping faster, reduced the
tedium of writing repetitive code, and opened up possibilities for rapid
development.</p>

<h2>Running Agents in Parallel</h2>

<p>Here&rsquo;s what&rsquo;s different now: you can run multiple AI agents at the same time,
each working on different problems. Instead of waiting for one agent to finish
a task before starting the next one, you can have several agents running
simultaneously - one building a user interface, another writing API endpoints,
and a third creating database schemas.</p>

<p>The core advantage is simple: you can do multiple things at once. This isn&rsquo;t
about smarter AI or better algorithms - it&rsquo;s about parallelization. The same
vibe coding tools we had before, just running multiple instances simultaneously.</p>

<p>The first company that offered a good solution for this was GitHub, with their
GitHub Co-Pilots that were running in the cloud. You basically go to an issue
and describe it on GitHub. When you are ready with all the descriptions that
you think should be able to describe the function, you assign it to Co-Pilot
and then wait for the result.</p>

<p>In practice, this means that you can go to your existing issues, check if
they have enough context to be handed over to AI. And then you wait
for the system to send you a notification that you can review the results.</p>

<p>This transforms the way you write code, and instead of focusing on the microsteps,
you are playing the role of a senior engineer who is guiding and providing context
to multiple agents who are implementing the features in your codebase. Your job as an
engineer now becomes reviewing the code for correctness, ensuring that proper
architectural decisions were taken, that a feature makes sense from the user&rsquo;s
perspective, and that the code meets all the security and compliance standards
that you need.</p>

<p>The agent itself has the same limitations as you would when you&rsquo;re vibe coding,
which means that they will have the same tendency to make bugs, to lack enough
context, to not understand the code. But you are as an engineer, and I would say
partly a product owner and designer, would guide the system to implement it
for you.</p>

<h2>How to work with multiple parallel agents</h2>

<p>Parallel agents are changing the way engineers work. Instead of focusing on one
task at a time, you can now coordinate several agents working on different
features or bug fixes in parallel. You‚Äôre actively managing multiple streams
of development, reviewing code, and providing feedback as each agent completes
its work.</p>

<p>With this approach, I can manage to have 10‚Äì20 pull requests open at once, each
handled by a dedicated agent.</p>

<p>Here are some practical steps to take:</p>

<p><strong>1. Prepare issues with sufficient context</strong></p>

<p>Start by ensuring each GitHub issue contains enough context for agents to
understand what needs to be built and how it integrates with the system. This
might include details about feature behavior, file locations, database
structure, or specific requirements such as displaying certain fields or
handling edge cases.</p>

<p><strong>2. Assign agents in batches</strong></p>

<p>Once issues are ready, assign them to AI agents (such as @copilot). Each
assignment typically starts a new pull request, where the agent creates a plan,
builds a checklist, and begins implementation. Multiple issues can be assigned
at once, allowing agents to work in parallel. Each individual agent takes
around 5-20 minutes to complete its work.</p>

<p><strong>3. Review and iterate locally</strong></p>

<p>After an agent completes its tasks, review the resulting pull requests locally.
Testing features and verifying correctness is essential. If changes are needed,
leave comments or feedback on the pull request, and the agent will continue
refining the solution.</p>

<p><strong>4. Maintain flow between reviews</strong></p>

<p>Unlike traditional workflows, parallel agent orchestration keeps me engaged
and focused. Instead of waiting for one agent to finish, it&rsquo;s possible to move
between active pull requests‚Äîreviewing, testing, and providing feedback
as needed. This enables simultaneous progress on multiple tasks without
significant mental overhead.</p>

<p>Here is a recording of how this works in practice:</p>

<div class="flex items-center justify-center">
<blockquote class="twitter-tweet" data-media-max-width="720"><p lang="en" dir="ltr">I&rsquo;m having an amazing time with delegated copilot agents, driving 10 pull-requests in parallel. Great work <a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github</a> üëè <a href="https://t.co/T6sCIBg6bH">pic.twitter.com/T6sCIBg6bH</a></p>&mdash; Igor ≈†arƒçeviƒá (@igor_sarcevic) <a href="https://twitter.com/igor_sarcevic/status/1958565202883957193?ref_src=twsrc%5Etfw">August 21, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<h2>What to Expect from Parallel Agents</h2>

<p>Working with parallel agents requires a different mindset than traditional or
vibe coding. The shift is as significant as moving from traditional coding to
AI-assisted development in the first place.</p>

<h3>Mental Model Changes</h3>

<p><strong>Control shifts from precision to orchestration.</strong> Instead of controlling every
line of code, you&rsquo;re managing multiple problems simultaneously. Think like a
system engineer managing Kubernetes pods rather than babysitting individual
servers - each task is expendable and replaceable.</p>

<p><strong>Everything becomes asynchronous.</strong> Unlike vibe coding where you wait and
watch, parallel agents work asynchronously by default. The context you provide
upfront determines the result 30 minutes later. You can&rsquo;t do half-hearted
prompts and fix as you go, because those fixes come an hour later.</p>

<p><strong>Batch thinking replaces linear thinking.</strong> Instead of picking one perfect task
from the backlog, identify several problems you could tackle in a day. A good
approach is focusing on 2 critical deliverables while running 5-10 small
background tasks - copy changes, UI fixes, minor bugs that can process while
you focus on important work.</p>

<h3>Realistic Success Rates</h3>

<p>Don&rsquo;t expect 100% success rates. Here&rsquo;s what typically happens based on my personal
observation while writing code.</p>

<ul>
<li><strong>10%</strong>: Perfect one-shot solution, ready to ship.</li>
<li><strong>20%</strong>: Almost there, needs 10 minutes of local refinement.</li>
<li><strong>40%</strong>: Needs manual intervention.</li>
<li><strong>20%</strong>: Completely wrong. Close the issue and write down learnings.</li>
<li><strong>10%</strong>: Bad product idea.</li>
</ul>

<p>Even if only 10% of the issues are solved perfectly by the agent, the process is
still valuable. Agents reliably handle the initial setup‚Äîfinding the right
files, writing boilerplate, and adding tests. By the time you review, much of
the groundwork is done, so you can focus on investigating and fixing specific
problems.</p>

<p>The frustration of engineers comes when they don&rsquo;t have a properly aligned
expectation of what they should expect from a coding agent. Some engineers
simply give up if they don&rsquo;t get the perfect 100% solution. I think you should
move past this limitation and just learn to extract the goodness while jumping
in with proper engineering knowledge where it needs to be.</p>

<h3>What Works Well vs. What Doesn&rsquo;t</h3>

<p><strong>Parallel agents excel at:</strong></p>

<ul>
<li>Bug fixes and race conditions</li>
<li>Backend logic, controllers, validations</li>
<li>Database changes and migrations</li>
<li>Package version bumps and code transformations</li>
<li>Small, well-defined implementation tasks</li>
</ul>

<p><strong>They struggle with:</strong></p>

<ul>
<li>New UI development (you need to see changes as you build)</li>
<li>Tasks requiring real-time visual feedback</li>
<li>Implementing undocumented additions to existing PRs</li>
<li>Complex architectural decisions requiring context beyond the issue</li>
</ul>

<h3>Skills That Become More Important</h3>

<p>Several traditional skills become even more valuable with parallel agents:</p>

<p><strong>Full-stack understanding</strong> is valuable when working with parallel agents. If
your expertise is limited to either frontend or backend, you&rsquo;ll quickly
encounter roadblocks. Agents often need guidance across the entire stack, from
database migrations to UI updates, so being able to navigate both worlds
ensures smoother collaboration and better results.</p>

<p><strong>Problem decomposition</strong> becomes a critical skill. Large, complex issues are
difficult for agents to tackle effectively. Breaking down big problems into
smaller, well-defined tasks allows agents to work independently and in
parallel, increasing the overall throughput and making it easier to review and
integrate their work.</p>

<p><strong>Good writting skills</strong> are important. Agents rely on the clarity and detail of your
issue descriptions to produce accurate results. Avoid vague language, unnecessary
jargon, or ambiguous requirements. The more specific and structured your
instructions, the higher the quality of the agent&rsquo;s output.</p>

<p><strong>QA and Code Review skills</strong> take center stage in this workflow. Since the
review cycle is the main bottleneck, being able to quickly assess code quality,
spot bugs, and verify that requirements are met is crucial. Efficient testing
and validation ensure that parallel development doesn&rsquo;t lead to a backlog of
unreviewed or faulty code.</p>

<p>When you are working with parallel agents, you should optimize for review speed.
You can start 50 issues, but you still need to review, understand, and verify
each one. Making that review cycle fast‚Äîideally under 10 seconds to check out,
rebuild, and test‚Äîbecomes critical to the entire workflow.</p>

<div class="flex items-center justify-center">
  <blockquote class="twitter-tweet" data-media-max-width="560"><p lang="en" dir="ltr">Learned a lot while using parallel <a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github</a> agents yesterday:<br><br>1/ My mental model was not prepared for parallel async work with agents<br>2/ You can&rsquo;t expect 100% success, but you can make a series of small bets<br>3/ Strategies to overcome blocking issues<br>4/ When to use Claude Code and‚Ä¶ <a href="https://t.co/yKNNkNZnby">pic.twitter.com/yKNNkNZnby</a></p>&mdash; Igor ≈†arƒçeviƒá (@igor_sarcevic) <a href="https://twitter.com/igor_sarcevic/status/1958895080166559749?ref_src=twsrc%5Etfw">August 22, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<h2>Engineering Practices That Enable Parallel Agents</h2>

<p>Working with parallel agents requires a well-structured engineering environment
that supports rapid iteration and review.</p>

<h3>Fast CI/CD Pipeline</h3>

<p>A robust CI/CD flow makes it easy to test and verify results. When agents
complete their work, you need to quickly validate that the changes work
correctly without manual deployment overhead. Automated testing, fast builds,
and seamless deployment processes remove friction from the review cycle. Without
this foundation, the bottleneck shifts from agent completion time to deployment
and testing time.</p>

<h3>System Documentation</h3>

<p>System architecture documentation helps when multiple agents work on different
parts of your codebase. Agents need to understand how components interact, where
files are located, what conventions are followed, and how different systems
integrate. Well-documented APIs, architectural decisions, coding standards, and
system boundaries help agents make better decisions and reduce the need for
manual corrections.</p>

<h3>Preview and Staging Environments</h3>

<p>A reliable staging environment where you can manually test features is required.
Since agents work asynchronously, you need a consistent place to validate their
output without affecting production systems. This environment should mirror
production, deploy quickly, and allow easy testing of multiple concurrent
changes. The ability to spin up isolated environments for different branches or
pull requests streamlines the parallel review process.</p>

<h3>Monorepo Architecture Benefits</h3>

<p>Keeping related services and components in a single monorepo works better when
working with parallel agents. A monorepo gives agents context about the entire
system within a single codebase.</p>

<p>When agents work across multiple repositories, they lose context about service
interactions, shared libraries, and dependencies. This leads to solutions that
work in isolation but break integration points. With a monorepo, agents
understand the full scope of changes needed - updating API contracts, adjusting
client code, and modifying shared utilities all in one pull request.</p>

<p>The unified view enables better architectural decisions. Agents can see existing
patterns, reuse common components, and maintain consistency across the system.
Code reviews are more effective because all related changes are visible in one
place, making it easier to verify that agents haven&rsquo;t introduced integration
issues.</p>

<p>Monorepos simplify deployment and testing for parallel development. Instead of
coordinating releases across multiple repositories, you can test complete system
changes together and deploy atomically. This reduces complexity when managing
multiple concurrent agent-generated changes across service boundaries.</p>

<h2>Tools That Support Parallel Agents</h2>

<p>Several development tools now support running parallel agents, each with
different strengths and maturity levels.</p>

<p><strong>GitHub Agents</strong> offer the most polished experience. They&rsquo;re integrated
directly into GitHub Issues and work seamlessly with VSCode. You assign issues
to @copilot, and agents create pull requests that you can review locally. There
are still some rough edges, but GitHub is addressing these issues one by one
with regular improvements.</p>

<p><strong>Cursor</strong> is currently experimenting with parallel agent support through a beta
program. They&rsquo;ve invited select users to test this functionality, and early
reports suggest it&rsquo;s a promising implementation. If you&rsquo;re already using Cursor
for vibe coding, their parallel agents might be worth exploring once they open
up broader access.</p>

<p><strong>OpenAI&rsquo;s Codex CLI</strong> also supports running agents in the cloud, which enables
this type of parallel development workflow. The CLI lets you start agents that
continue running remotely, allowing you to manage multiple concurrent coding
tasks without keeping your local environment tied up.</p>

<p>Each tool takes a slightly different approach to parallel execution, so the best
choice depends on your existing development workflow and tool preferences.</p>

<h2>Wrapping Up</h2>

<p>I&rsquo;ve been working with parallel agents for a few weeks now, and it&rsquo;s changed
how I approach development. The ability to work on multiple problems
simultaneously, rather than sequentially, makes a real difference in
productivity.</p>

<p>The technology isn&rsquo;t perfect - you&rsquo;ll spend time reviewing and fixing
agent-generated code. But when you can kick off 10 tasks and have most of them
move forward without your direct involvement, it frees up mental bandwidth for
the problems that actually need human judgment.</p>

<p>If you&rsquo;re curious about trying this approach, start with small, well-defined
issues in your backlog. Write clear descriptions and see what happens. The worst
case is you spend a few minutes reviewing code that doesn&rsquo;t work. The best case
is you discover a new way of working that fits your development style.</p>

      </div>
    </article>
  </div>


      <div class="w-100 my-16">
  <div class="text-center text-lg">
    <p>
      <strong>‚ùà</strong><br>
      <br>

      Follow me on <a href="https://twitter.com/igor_sarcevic" class="link">X</a> and <a href="https://rs.linkedin.com/in/igorsarcevic" class="link">LinkedIn</a>.<br>
      ¬© 2025 Igor ≈†arƒçeviƒá.
    </p>
  </div>
<div>

    </div>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
       (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
         m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
           })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-57223799-1', 'auto');
      ga('send', 'pageview');
    </script>

    <script>
      /**
      * Function that tracks a click on an outbound link in Analytics.
      * This function takes a valid URL string as an argument, and uses that URL string
      * as the event label. Setting the transport method to 'beacon' lets the hit be sent
      * using 'navigator.sendBeacon' in browser that support it.
      */
      var trackOutboundLink = function(url) {
        ga('send', 'event', 'outbound', 'click', url, {
          'transport': 'beacon',
          'hitCallback': function(){document.location = url;}
        });
      }
    </script>

  </body>
</html>
