<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>The path of coding enlightment</title>
  <id>http://shiroyasha.io/</id>
  <link href="http://shiroyasha.io/"/>
  <link href="http://shiroyasha.io/feed.xml" rel="self"/>
  <updated>2024-10-06T00:00:00+00:00</updated>
  <author>
    <name>Igor Šarčević</name>
  </author>
  <entry>
    <title>Social Parasites</title>
    <link rel="alternate" href="http://shiroyasha.io/social-parasites.html"/>
    <id>http://shiroyasha.io/social-parasites.html</id>
    <published>2024-10-06T00:00:00+00:00</published>
    <updated>2024-10-06T18:32:13+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;We’ve recently witnessed a perfect example of this parasitic behavior. A
startup, freshly minted by a once-respected incubator, had the audacity to fork
an open-source project and claim it as their own. They didn’t innovate. They
didn’t improve. They...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;We&amp;rsquo;ve recently witnessed a perfect example of this parasitic behavior. A
startup, freshly minted by a once-respected incubator, had the audacity to fork
an open-source project and claim it as their own. They didn&amp;rsquo;t innovate. They
didn&amp;rsquo;t improve. They simply took.&lt;/p&gt;

&lt;p&gt;Let me be clear: I&amp;rsquo;m not talking about healthy competition or even inspiration
drawn from existing ideas. I&amp;rsquo;m talking about those who shamelessly and completely
take the hard work of others, wrapping it in a shiny new package and calling it
their own.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s what happened: This startup PairAI basically took an open-source project 
called Continue, forked it, and are now passing it off as their own groundbreaking
innovation.&lt;/p&gt;

&lt;p&gt;And here&amp;rsquo;s the kick-you-in-the-balls: YC&amp;rsquo;s CEO, Garry Tan, defended this copycat
behavior on Twitter. Talk about missing the forest for the trees. Sure, it might
be legal, but that&amp;rsquo;s not the point. The point is that YC is funding startups 
with zero innovation and apparently zero due diligence.&lt;/p&gt;

&lt;p&gt;Being inspired by other projects is one thing. Heck, it&amp;rsquo;s how most of us get
started. I&amp;rsquo;m even fine with copying. But taking someone else&amp;rsquo;s work, changing a 
few lines of code, and calling it your own, and then apply to YC and get funded? 
That&amp;rsquo;s a whole different story.&lt;/p&gt;

&lt;p&gt;Now, some might argue that open-source licenses permit such actions. But let me
ask you this: Since when did we start confusing what&amp;rsquo;s legally permissible with
what&amp;rsquo;s ethically right? Since when did &amp;ldquo;not illegal&amp;rdquo; become the bar we&amp;rsquo;re aiming 
for in the tech industry?&lt;/p&gt;

&lt;p&gt;What message does this send to open-source projects? To the builder and the
maintainers who pour their hearts and souls into open-source projects? It tells
them that their work is up for grabs, ready to be exploited by the first
opportunist who comes along.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the thing: Open-source isn&amp;rsquo;t just about the license. It&amp;rsquo;s about the
community. It&amp;rsquo;s about giving back, not just taking. When we use open-source
tools at Operately (and we use them a lot), we always look for ways to contribute
back. Sometimes it&amp;rsquo;s code, sometimes it&amp;rsquo;s documentation, sometimes it&amp;rsquo;s just
reporting bugs. But we contribute. Because that&amp;rsquo;s how healthy ecosystems work.&lt;/p&gt;

&lt;p&gt;So what can we do about it?&lt;/p&gt;

&lt;p&gt;First, if you&amp;rsquo;re an open-source maintainer or contributor, don&amp;rsquo;t let this
discourage you. Keep building, keep sharing. The actions of a few bad actors
don&amp;rsquo;t negate the immense value and importance of what you do. Open-source is
still one of the most powerfull fonces for good, not only in tech, but for the
whole world and society.&lt;/p&gt;

&lt;p&gt;Second, to the folks at YC: It&amp;rsquo;s time to step on the brakes. Remember what made
you special in the first place. It wasn&amp;rsquo;t the number of startups you funded. 
It was the quality. The innovation. The community. You are letting it slip
away. For what? A quick flip? A few more unicorns? Is that really worth it?&lt;/p&gt;

&lt;p&gt;Building a successful project is hard. Building a successful company is even
harder. Really hard. There are no shortcurts. And if there were, they certainly 
wouldn&amp;rsquo;t involve ripping off the hard work of others.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s call this behavior what it is: parasitic. And let&amp;rsquo;s make sure it has no
place in our industry. &lt;/p&gt;

&lt;p&gt;&amp;mdash; Igor&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Manage Your Time or Someone Else Will Do It for You</title>
    <link rel="alternate" href="http://shiroyasha.io/manage-your-time-or-someone-else-will-do-it-for-you.html"/>
    <id>http://shiroyasha.io/manage-your-time-or-someone-else-will-do-it-for-you.html</id>
    <published>2024-08-25T00:00:00+00:00</published>
    <updated>2024-10-06T18:32:12+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;From the moment we’re born, our time isn’t really our own. Parents, schools,
and later, employers all have a say in how our days unfold. As kids, we’re on
someone else’s schedule. Education systems beat it into us, training us to
march to the drum...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;From the moment we’re born, our time isn’t really our own. Parents, schools,
and later, employers all have a say in how our days unfold. As kids, we’re on
someone else’s schedule. Education systems beat it into us, training us to
march to the drum of a clock that someone else controls. By the time we enter
the workforce, we’re well-prepared to hand over the reins of our time to
another authority.&lt;/p&gt;

&lt;p&gt;Most people never break free from this pattern. They move from the structure of
school into the rigid framework of corporate life, where time is often wasted
on pointless tasks. Think about the endless meetings you’ve sat
through—meetings that could have been an email, a quick chat, or even avoided
entirely. It’s astonishing how much time we collectively waste on rituals that
serve no real purpose.&lt;/p&gt;

&lt;p&gt;The office itself is a masterclass in time-wasting. Long commutes eat away at
your day. Two hours stuck in traffic might not seem like much, but add that up
over a week, a month, a year. Suddenly, you’ve lost hundreds of hours that
could have been spent on something meaningful. That’s time you could’ve used to
learn a new skill, start a side project, or just have some damn fun. Adventures
don’t just happen—they’re made, and you need time to make them.&lt;/p&gt;

&lt;p&gt;Complete work-life separation isn’t optimal either. When you rigidly divide
work from the rest of your life, you end up competing for time and space with
everyone else. The classic example is the gym at 5 p.m. It’s packed, loud, and
stressful. Go at noon, though, and it’s a different world. You have space, you
have time, and you have freedom. Why not work when you’re most productive, and
live when it’s most enjoyable?&lt;/p&gt;

&lt;p&gt;If you measure your team’s output by the hours they spend in a chair, you’re
doing it wrong. It’s naive and lazy management. Forcing people to be present
for a fixed number of hours is a waste, plain and simple. It’s not about the
time spent; it’s about what gets done. When you value chair time over actual
work, you’re collectively making everyone’s life worse. You’re stealing time
from them—their most valuable asset.&lt;/p&gt;

&lt;p&gt;The truth is, if you don’t take control of your time, someone else will. And
they’ll do it in a way that benefits them, not you. Don’t let that happen. Take
the reins, cut out the waste, and reclaim your time. It’s the only way to live
a life that’s truly yours.&lt;/p&gt;

&lt;p&gt;&amp;mdash; Igor&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Steps We Took to Automate License Compatibility Verification</title>
    <link rel="alternate" href="http://shiroyasha.io/steps-we-took-to-automate-license-compatibility-verification.html"/>
    <id>http://shiroyasha.io/steps-we-took-to-automate-license-compatibility-verification.html</id>
    <published>2024-04-14T00:00:00+00:00</published>
    <updated>2024-10-06T17:48:38+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;We are actively developing Operately, an open-source software licensed under
Apache 2.0. As such, we need to carefully consider whether our dependencies’
licenses are compatible with ours. Starting to build features based on
functionality from a non...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;We are actively developing Operately, an open-source software licensed under
Apache 2.0. As such, we need to carefully consider whether our dependencies&amp;rsquo;
licenses are compatible with ours. Starting to build features based on
functionality from a non-compatible license, only to realize this too late,
could lead to wasted time and energy in rewriting those features.&lt;/p&gt;

&lt;p&gt;As we are a small team, my attention is intensely focused on building and
refining the core features of Operately. Whenever possible, I take
opportunities to automate tasks that can save significant time in the coming
months. One question arises: can license compatibility checks be automated to a
reasonable degree within a day&amp;rsquo;s work, with a return on the time invested over
the next few months? I implemented such a system a few months ago at Operately.
The return on investment has been decidedly positive, and on several occasions,
it has prevented me from proceeding with features based on an incompatible AGPL
license—a scenario that could have cost me weeks or even a full month of work
if not caught early.&lt;/p&gt;

&lt;p&gt;My requirements for a license compatibility checking system are as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Integration into the CI Build &amp;amp; Test Phase&lt;/strong&gt;: The system should be
integrated into every continuous integration (CI) run. Whenever someone
pushes code or opens a pull request, the system must provide a clear YES/NO
answer regarding license compatibility. I prefer this real-time check over
asynchronous systems that only notify of issues after code submission.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Comprehensive Dependency Testing&lt;/strong&gt;: The solution must be capable of
testing not only direct dependencies but also their nested dependencies
recursively. It is crucial that it supports Elixir libraries and NPM packages,
given that Operately is developed with a combination of Elixir and React. While
Docker build compatibility would be beneficial, it is not essential.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Open-Source&lt;/strong&gt;: The solution should be open-source. We are committed to
supporting and utilizing open-source solutions, aligning with our principles
and contributing back to the community.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href="https://github.com/pivotal/LicenseFinder"&gt;Pivotal’s License Finder&lt;/a&gt; is an 
excellent solution that meets most of our needs. It is a Ruby-based CLI tool 
that can be installed in our repository and integrated into our continuous 
integration build process. It is compatible with Elixir Mix and NPM, which are
essential for Operately, given our use of Elixir and React. Additionally, it 
supports many other programming languages and build systems, offering flexibility
should we decide to incorporate other technologies into Operately in the future.&lt;/p&gt;

&lt;p&gt;The initial setup of the License Finder can be complex as it involves listing
all the dependencies in your projects and requiring approval for each
discovered license. Here’s the strategy I recommend:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Approve MIT and BSD Licenses&lt;/strong&gt;: These licenses are well-established,
clearly written, and have judicial precedence confirming their compatibility
with the Apache 2.0 license. Approving these is straightforward.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Assess Other Open Source Licenses&lt;/strong&gt;: Navigating other open-source licenses
can be more challenging. &lt;a href="https://opensource.org/license"&gt;OpenSource.org&lt;/a&gt; lists 
at least 10 pages of recognized open-source licenses. Some, like GPL3 and AGPL, 
are not compatible with Apache 2.0 and are considered restrictive or even
parasitic. Others, such as Unlicense or WTFPL, lack clear legal status and
are potentially problematic. Since I&amp;rsquo;m not a lawyer, we have decided not to use
such licenses.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Handle Unknown Licenses&lt;/strong&gt;: License Finder sometimes cannot identify a
license for a dependency, like with TipTap used for rich text editing. In
these cases, License Finder allows for the manual approval of packages. It
requires you to specify your identity, the basis of your authorization, and
the reason for approving the use of the license.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Deal with License-Less Dependencies&lt;/strong&gt;: Many public repositories on GitHub
are intended to be open-source but lack a clear license, making their use
legally risky. I recommend removing these dependencies or contacting the
contributors to obtain permission to use their software.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Automate the Process&lt;/strong&gt;: Once you have approved all licenses, you can
automate the process by running License Finder in CI. It will check all
dependencies and provide a report on the licenses used. If a new dependency
is added, License Finder will notify you of the new license, allowing you to
approve or reject it.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once the setup and initial license triage are completed, this system requires
almost no maintenance. It will continuously check every new dependency and every
update to your existing dependencies in the background.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A note of warning:&lt;/strong&gt; While this system is great at detecting most license
incompatibilities, it is not infallible. I recommend a periodic manual reviews 
of all your dependencies, particularly for infrastructure software that this 
solution does not cover.&lt;/p&gt;

&lt;p&gt;By investing a day in setting up the License Finder, I have saved myself weeks
of potential rework and legal headaches. I highly recommend this system to
anyone working on open-source projects, especially those with a small team and
limited resources. It is a small investment that can prevent significant
headaches down the road.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Investing time and energy into automation can yield long-term benefits, but there
is a risk of automating too much too early. For instance, for an early startup
like Operately, it makes sense to automate processes that can provide positive
outcomes within the upcoming quarter and can be completed in under a day.
However, it would be unwise to spend several weeks on automation efforts that do
not promise returns in the foreseeable future.&lt;/p&gt;

&lt;p&gt;Finally, if you want to look at the specifics of how we implemented this check,
start from here: &lt;a href="https://github.com/operately/operately/blob/main/Makefile#L216"&gt;Operately Makefile&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Adulting Harder</title>
    <link rel="alternate" href="http://shiroyasha.io/adulting-harder.html"/>
    <id>http://shiroyasha.io/adulting-harder.html</id>
    <published>2023-01-29T00:00:00+00:00</published>
    <updated>2024-10-06T17:48:38+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;One of my grandad’s best friends, Kovács János, was a talented chess player.
They used to play chess together every week. János consistently beat my grandpa,
but winning was not the focus of their play. It was a dedicated time to talk about
life, women...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;One of my grandad&amp;rsquo;s best friends, Kovács János, was a talented chess player.
They used to play chess together every week. János consistently beat my grandpa,
but winning was not the focus of their play. It was a dedicated time to talk about
life, women, and their shared admiration for Ferenc Puskás, a famous
Hungarian football player.&lt;/p&gt;

&lt;p&gt;Despite his high intellect, János was struggling to put his life together.
He would often drink to excess and lose vast amounts of money to gambling.
He struggled to hold down a job and had a hard time being accountable
for his actions.&lt;/p&gt;

&lt;p&gt;It all changed when his wife left him, taking away his two children.
While he was always very persistent about how much he loved his wife,
his actions told a different story. Frequently drunk, losing money,
and flirting around with other married women in the town, he lost
any remaining love his wife had for him. János hit rock bottom.
He lost his wife, children, and most of his friends.&lt;/p&gt;

&lt;p&gt;Despite his struggles, my grandad never gave up on János. He knew that
there was a capable person beneath all of the gambling and
irresponsibility. My grandpa gave János a stern but loving speech at one
of their weekly chess sessions. &amp;ldquo;Look, János, I like you as a friend
and respect you as a chess player, but you need to learn to be an adult.
You need to be able to take responsibility.&amp;rdquo; His intellect was undeniable,
but his habits were more akin to a teenager than a grown, responsible man.&lt;/p&gt;

&lt;p&gt;My grandpa repeated the same message to János for years, but he was
ready to change this time. He changed his life around almost overnight.
He stopped drinking and gambling and separated himself from a group of
friends who only supported him while living a reckless, irresponsible life.&lt;/p&gt;

&lt;p&gt;My grandpa found a mechanical support position for him at the local
military unit, where he slowly learned how to act and behave like a
grownup. Several years later, János opened up a side business in his
backyard where he was working as a car mechanic.&lt;/p&gt;

&lt;p&gt;In his retirement, János was my chess teacher for a brief period,
sharing stories about my late grandad and the lessons they learned
during their life. János&amp;rsquo;s story is a reminder that no matter how
hard life gets, it&amp;rsquo;s never too late to turn things around. With the
right mindset, determination, and support, anyone can overcome their
struggles and build a better life for themselves, their family,
and their friends.&lt;/p&gt;

&lt;p&gt;János, despite being an adult, was still a teenager in his late thirties.
The lesson I learned from János was that real success requires us to adult
harder. Take challenges head-on, build a system of accountability,
forge strong friendships, and strongly believe in people and yourself
despite any mistake in the past.&lt;/p&gt;

&lt;h2&gt;What can we learn from János about adulting harder?&lt;/h2&gt;

&lt;p&gt;Despite literally being the definition of adulthood, adulthood
doesn&amp;rsquo;t start by turning 18 or 21. It begins by taking responsibility.
Responsibility to hold down a stable job, provide for your family, and
become a positive force for your community.&lt;/p&gt;

&lt;p&gt;Adulting harder goes beyond just paying bills. It&amp;rsquo;s also about
taking on challenges and making the most of the opportunities
that come your way.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Pull Requests are a reflection of your engineering culture</title>
    <link rel="alternate" href="http://shiroyasha.io/pull-requests-are-a-reflection-of-your-engineering-culture.html"/>
    <id>http://shiroyasha.io/pull-requests-are-a-reflection-of-your-engineering-culture.html</id>
    <published>2022-07-17T00:00:00+00:00</published>
    <updated>2024-10-06T17:48:38+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;When engineers want to introduce a change to the system, they use pull requests
to package the change and present it to the rest of the team. A pull request
usually contains a title, a description, and a list of commits that aim to
change the system...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;When engineers want to introduce a change to the system, they use pull requests
to package the change and present it to the rest of the team. A pull request
usually contains a title, a description, and a list of commits that aim to
change the system.&lt;/p&gt;

&lt;p&gt;They are the core communication mechanism in your team. More precise than Jira
tickets, more pragmatic than any meeting, and more direct than any design
document. Take a random pull request from your team, and it will tell me more
about your engineering culture than any other metric.&lt;/p&gt;

&lt;h2&gt;Comparing Good and Bad pull requests&lt;/h2&gt;

&lt;p&gt;A pull request should be easy to understand. It should be reasonably short. It
should be backed by clear, objective quality signals like green CI build and
code quality metrics.&lt;/p&gt;

&lt;p&gt;Bad pull requests are unclear. They don&amp;rsquo;t have clear answers to &amp;ldquo;why are we
doing this?&amp;rdquo; and &amp;ldquo;why are we doing it like this?&amp;rdquo;. They are usually unreasonable
in size and include multiple changes to multiple subsystems. The reader is
typically unsure if the pull request is mergeable, nor does he have any metric
to help answer this question.&lt;/p&gt;

&lt;h2&gt;Write clear titles&lt;/h2&gt;

&lt;p&gt;Clear titles that signal what this pull request is about to
introduce. Typically, this is a combination of business needs and concrete
implementation approaches.&lt;/p&gt;

&lt;p&gt;As with other forms of writing, there is no precise formula for titles. It is
one of those things that you recognize when you see it.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at some examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&amp;ldquo;Change src/scheduler.go&amp;rdquo; - A good indication of poor communication patterns in
the team. Usually, these are individual contributors who rarely work in a
structured group.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&amp;ldquo;Update the for loop in the scheduler implementation by counting in reverse and
visiting memory objects in a FIFO order&amp;rdquo; - Technically precise, but low
information about the reason for this change. Usually, an indication of poor
communication in the team and can be a signal of superhero culture.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&amp;ldquo;Optimization of the scheduling strategy&amp;rdquo; - Good high-level technical overview,
but still low information about the reason for this change. Typically, it arises
in teams disconnected from the company&amp;rsquo;s business decisions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&amp;ldquo;Optimization of the scheduling strategy to reduce server hosting costs -
Excellent! Good technical description and direct reason for this change. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Focus on the reason for change in the description&lt;/h2&gt;

&lt;p&gt;Every change to the system has two parts: the &lt;em&gt;why?&lt;/em&gt; and the &lt;em&gt;how?&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;how?&lt;/em&gt; should be clear from the code. Either write clean and understandable
code or supplement the code with documentation that describes the implementation
details.&lt;/p&gt;

&lt;p&gt;As the code focuses on the &lt;em&gt;how?&lt;/em&gt;, there is little reason to supplement this
same information in the pull request description. The description should
describe the details of why we are introducing this change.&lt;/p&gt;

&lt;p&gt;For example, here is how a good PR description should look like. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We have noticed increased server hosting costs in the previous
quarter that were not matched directly by increased demand on the system. We
have noticed that the scheduling system is introducing delays by not efficiently
visiting the objects. This PR addresses this concern and aims to reduce the
server hosting costs by up to 5%.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Notice that it focuses on the reason and not the implementation.&lt;/p&gt;

&lt;h2&gt;Supplement PRs with results and visual proof&lt;/h2&gt;

&lt;p&gt;Pull Request reviewers will typically question your approach to solving the 
problem or might be unsure of the results.&lt;/p&gt;

&lt;p&gt;Provide results or visual proof when submitting pull requests. In our previous
scheduling example, provide metric data that supports your argument. In visually
centered systems, like updates in the UI, provide screenshots or videos of the
new design. &lt;/p&gt;

&lt;h2&gt;Keep the Pull Requests short and to the point&lt;/h2&gt;

&lt;p&gt;I have a rule of thumb in my team. Pull requests should be short in length 
(typically around ~300loc), short in age (0-3 days to write), and focused on one change.&lt;/p&gt;

&lt;p&gt;Typically, a pull request starts by updating tests, followed by several commits
that attempt to implement the new system specification.&lt;/p&gt;

&lt;p&gt;Long pull requests are typically a signal of either young engineers who are
still learning the value of short and safe iterative changes or overly eager
changes to the system that is impossible to review and approve.&lt;/p&gt;

&lt;p&gt;The actual number of line changes depends on multiple factors. The previously
mentioned ~300loc fits my team and our design. Some languages are less
expressive, and some changes require more work and cannot be broken down. &lt;/p&gt;

&lt;p&gt;Breaking these guidelines once in a while is not a problem. The problem arises
when suboptimal patterns take over and degrade your engineering culture.&lt;/p&gt;

&lt;h2&gt;Keep the coding style uniform and objective&lt;/h2&gt;

&lt;p&gt;Young engineering teams tend to put a lot of emphasis on how the code looks and 
how it is formatted. Older teams usually have a shared understanding of what 
good code looks like and spend less time discussing it.&lt;/p&gt;

&lt;p&gt;Keeping the code clean has clear benefits. But discussing this in every pull
request degrades the quality of discussion and exhausts the energy that remains
for vital topics.&lt;/p&gt;

&lt;p&gt;Use a linter, codify your rules, and make it part of the CI process. There
should be no reason to check the code style in every pull request manually.&lt;/p&gt;

&lt;h2&gt;Don&amp;rsquo;t review pull requests before CI&lt;/h2&gt;

&lt;p&gt;The CI should be your first reviewer. There is no reason to involve other humans
before you get a green build from your CI system.&lt;/p&gt;

&lt;p&gt;Teams that lack fast CI, or even worse, lack CI entirely, tend to lose a lot of
time repeating and manually validating the same problem areas over and over.&lt;/p&gt;

&lt;p&gt;An engineering culture that lacks automated Pull Request reviews is an insane
amount of energy and money on entirely automatable problems.&lt;/p&gt;

&lt;h2&gt;Tips for engineering leadership&lt;/h2&gt;

&lt;p&gt;It is understandably hard to step out from thinking about long-term strategy and 
zoom in on a single pull request. However, by missing to do this occasionally 
(once a quartal, for example), you are missing out on valuable insights about
your engineering culture that are hard to reproduce in any other way.&lt;/p&gt;

&lt;p&gt;After all, it has been repeatably shown that your organization&amp;rsquo;s operational
performance directly impacts its overall performance.&lt;/p&gt;

&lt;p&gt;My advice is to go to your main project, take a random pull request, and get a
direct first-hand experience of the bottlenecks your team is dealing with.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Proactive cache warming in a microservice-based architecture</title>
    <link rel="alternate" href="http://shiroyasha.io/proactive-cache-warming-in-a-microservice-based-architecture.html"/>
    <id>http://shiroyasha.io/proactive-cache-warming-in-a-microservice-based-architecture.html</id>
    <published>2021-07-17T00:00:00+00:00</published>
    <updated>2024-10-06T17:48:38+00:00</updated>
    <author>
      <name>Igor Šarčević</name>
    </author>
    <summary type="html">&lt;p&gt;With the microservice architecture style, services and their data are contained
within a single bounded context. This architectural decision helps us to develop
and deploy changes in one business unit fast and independent of other services
in our system...&lt;/p&gt;</summary>
    <content type="html">&lt;p&gt;With the microservice architecture style, services and their data are contained
within a single bounded context. This architectural decision helps us to develop
and deploy changes in one business unit fast and independent of other services
in our system.&lt;/p&gt;

&lt;p&gt;However, collecting and analyzing data from multiple services can be slow and
much more complex than in a typical monolithic service where the caller has
access to data from a single big database system.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at an example: A web application for ordering items with a page that
displays information about the most recent orders in a company.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/proactive-caching/architecture-example.png" alt="Proactive Cache Warming: Architecture Example" /&gt;&lt;/p&gt;

&lt;p&gt;We will focus on the front service from the above architecture. More
specifically, on its recent orders controller action.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;OrdersService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;customer_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="ss"&gt;:customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;CustomerService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_customer_details&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;render_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Our next challenge is how to make this page fast.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s assume for the sake of the argument that both the Orders Service and the
Customer Services take around 200ms to respond and that we don&amp;rsquo;t have any viable
way of making these response times faster.&lt;/p&gt;

&lt;p&gt;To render the page, we need to wait 200ms for the Orders Service, then 200ms for
the Customers Service, and finally, we need some time to generate the HTML page,
100ms. The minimum time to render the page is 500ms, which is relatively slow.&lt;/p&gt;

&lt;p&gt;Caching is a standard tool that we use to make slow things faster. Key/Value
memory stores like Redis can easily support 1ms response times if we figure out
how to use it effectively.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s explore some caching strategies.&lt;/p&gt;

&lt;h2&gt;Time-to-live based caching&lt;/h2&gt;

&lt;p&gt;A simple-to-implement caching strategy is a time-based one. This strategy
renders the page and keeps it in the cache for a given amount of time.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="no"&gt;CACHE_EXPIRES_IN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;hour&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;cached_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cached_page&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
    &lt;span class="n"&gt;cached_page&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;ttl: &lt;/span&gt;&lt;span class="no"&gt;CACHE_EXPIRES_IN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;content&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="s2"&gt;"recent_orders_page_&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;OrdersService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;customer_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="ss"&gt;:customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;CustomerService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_customer_details&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;render_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This strategy can be the ideal one when the domain of the problem is time-bound.
For example, if the page would display orders processed for the previous day
instead of listing all the most recent ones.&lt;/p&gt;

&lt;p&gt;The most significant downside is that the page will not refresh its content even
if the system receives new orders. The page will be fast but stale.&lt;/p&gt;

&lt;h2&gt;Signature-based caching&lt;/h2&gt;

&lt;p&gt;We can use this information to optimize our rendering function.  Another way to
improve the speed of our page is to fetch some minimal amount of data that can
signal to our system if our cached value is stale or usable.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s assume that in the above example, the order processing system has an
additional endpoint that can tell us the timestamp of the last processed order
by a given company in 100ms.&lt;/p&gt;

&lt;p&gt;We can use this information to optimize our rendering function.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;last_order_at&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;OrdersService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_last_order_timestamp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last_order_at&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;cached_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cached_page&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
    &lt;span class="n"&gt;cached_page&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;ttl: &lt;/span&gt;&lt;span class="no"&gt;CACHE_EXPIRES_IN&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;content&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last_order_at&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="s2"&gt;"recent_orders_page_&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;_&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;md5&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_order_at&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;OrdersService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;customer_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="ss"&gt;:customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;CustomerService&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;get_customer_details&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;customer_ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;render_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above implementation makes sure that we never have a stale state on the
page. However, the performance gains are not so good as in our previous
iteration.&lt;/p&gt;

&lt;p&gt;If we have a cache hit, the performance will be 100ms as it takes this long to
fetch the timestamp of the last order.&lt;/p&gt;

&lt;p&gt;If we have a cache miss, the performance will be worse than it would be without
caching. We will need 100ms to find the timestamp of the last order, plus the
500ms duration for the full page render.&lt;/p&gt;

&lt;h2&gt;Event-based caching&lt;/h2&gt;

&lt;p&gt;In both of the previous implementations, the core problem was how and when to
clear the cached values. It turns out it is pretty hard to deduce this on the
client-side.&lt;/p&gt;

&lt;p&gt;One strategy common in distributed systems is to use events to propagate
information about state changes. We can use this architecture to have a clear
signal of when to clear our cache.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/proactive-caching/invalidation.png" alt="Proactive Cache Warming: Event Based Cache Invalidation" /&gt;&lt;/p&gt;

&lt;p&gt;In this architecture, both the order processing service and the customer service
are publishing events when their datasets change. The cache invalidator then
listens to those events and clears the data from the UI layer&amp;rsquo;s cache.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;cached_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;cached_page&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;present?&lt;/span&gt;
    &lt;span class="n"&gt;cached_page&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;
    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;content&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;subscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"orders_service"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"order-created"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;clear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;subscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"customers_service"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"customer-updated"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;clear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We get pretty fast response times and up-to-date content in the cache. Neat!&lt;/p&gt;

&lt;p&gt;If we have a cache hit, we can respond under 1ms, the amount of time it takes to
fetch the data from the cache.&lt;/p&gt;

&lt;p&gt;If we have a cache miss, we can respond in 500ms, the amount of data it takes to
have a full page render.&lt;/p&gt;

&lt;p&gt;The event-based cache invalidation is better in both cases from the
signature-based caching solution we explored in the previous section.&lt;/p&gt;

&lt;h2&gt;Event-based proactive caching&lt;/h2&gt;

&lt;p&gt;We had a 1ms response for cached pages in that last section and 500ms for when
the page wasn&amp;rsquo;t cached. Can we do better?&lt;/p&gt;

&lt;p&gt;One approach that can guarantee a fast (1ms) response is to utilize proactive
caching, meaning to prepare the page cache before the customers load it for the
first time.&lt;/p&gt;

&lt;p&gt;&lt;img src="/images/proactive-caching/reactor.png" alt="Proactive Cache Warming: Event Based Cache Updater" /&gt;&lt;/p&gt;

&lt;p&gt;In this architecture, the UI layer always reads responses from the cache,
meaning that it can guarantee a fast response time for both first visits and
repeated visits to the page.&lt;/p&gt;

&lt;p&gt;The reactor maintains the cache&amp;rsquo;s content, a subsystem in the UI layer that
reacts to various events in the system and recalculates the cached content.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;recent_orders&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;cached_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;cached_page&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;subscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"orders_service"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"order-created"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;new_content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;subscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"customers_service"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"customer-updated"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt;
  &lt;span class="n"&gt;key&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cache_key&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;new_content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;full_render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;company_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="no"&gt;Cache&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;store&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let&amp;rsquo;s analyze this pattern. What are the shortcomings of this caching approach?&lt;/p&gt;

&lt;p&gt;On the pros side, this caching approach can guarantee us fast response times for
every page visit.&lt;/p&gt;

&lt;p&gt;On the cons side, the reactor might be caching pages that our customers rarely
visit, which leads to lots of busywork in our system. We might prepare and
crunch an enormous amount of unused data.&lt;/p&gt;

&lt;p&gt;The storage size can also drastically increase when we start using this approach
as we are no longer storing only visited pages but all the pages in the cache.&lt;/p&gt;

&lt;p&gt;If your number one priority is speed, the added storage and architectural
complexity could be acceptable; otherwise, you might be crunching data
needlessly. Choose carefully.&lt;/p&gt;

&lt;p&gt;&lt;hr style="width: 50%; margin-top: 3em; border-color: gray;"&gt;&lt;/p&gt;

&lt;p&gt;Caching is complicated, even more so in distributed systems.&lt;/p&gt;

&lt;p&gt;At &lt;a href="https://semaphoreci.com"&gt;SemaphoreCI&lt;/a&gt;, we use event-based proactive caching
to make our UI layer fast.  Over the years, we faced many challenges while using
this system, including race conditions and high queue processing latency.
However, while these problems were challenging, we are still happy with this
architectural choice even after several years in production.&lt;/p&gt;

&lt;p&gt;Here are some great resources for further reading:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://martinfowler.com/bliki/ReportingDatabase.html"&gt;Reporting Database&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.oreilly.com/library/view/microservices-antipatterns-and/9781492042716/"&gt;Microservices: AntiPatterns and Pitfalls&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://martinfowler.com/articles/201701-event-driven.html"&gt;What do you mean by “Event-Driven”?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
</feed>
